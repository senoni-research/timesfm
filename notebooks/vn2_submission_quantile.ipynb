{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VN2 Submission: TimesFM 2.5 Quantile Forecasting Demo\n",
        "\n",
        "**Purpose**: Demonstrate TimesFM 2.5's quantile head for VN2 inventory planning\n",
        "\n",
        "**Approach**:\n",
        "1. Load all 599 SKUs from VN2\n",
        "2. Generate quantile forecasts (P10-P90) using TimesFM 2.5\n",
        "3. Select cost-optimal quantile: Cu/(Cu+Co) = 1.0/(1.0+0.2) = 0.833\n",
        "4. Convert to order quantities using base-stock policy\n",
        "5. Generate submission CSV\n",
        "\n",
        "**Note**: This is a DEMO of quantile forecasting capabilities, not competing with the official hierarchical Bayes submission.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# TimesFM\n",
        "import torch\n",
        "timesfm_path = Path(\"..\").resolve()\n",
        "if str(timesfm_path) not in sys.path:\n",
        "    sys.path.insert(0, str(timesfm_path))\n",
        "import timesfm\n",
        "\n",
        "# VN2 policy helpers\n",
        "vn2_path = Path(\"../../vn2inventory\").resolve()\n",
        "if str(vn2_path) not in sys.path:\n",
        "    sys.path.insert(0, str(vn2_path))\n",
        "from vn2inventory.policy import compute_orders\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VN2 Configuration\n",
        "DATA_DIR = Path(\"../../vn2inventory/data\").resolve()\n",
        "SUB_DIR = Path(\"../../vn2inventory/submissions\").resolve()\n",
        "SUB_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Costs (from VN2 competition)\n",
        "SHORTAGE_COST = 1.0\n",
        "HOLDING_COST = 0.2\n",
        "LEAD_WEEKS = 2\n",
        "REVIEW_WEEKS = 1\n",
        "PROTECTION_WEEKS = LEAD_WEEKS + REVIEW_WEEKS  # 3 weeks\n",
        "\n",
        "# Critical fractile (Newsvendor optimal service level)\n",
        "CRITICAL_RATIO = SHORTAGE_COST / (SHORTAGE_COST + HOLDING_COST)\n",
        "print(f\"\\\\n📊 VN2 Cost Structure:\")\n",
        "print(f\"  Shortage cost (Cu): ${SHORTAGE_COST}\")\n",
        "print(f\"  Holding cost (Co): ${HOLDING_COST}\")\n",
        "print(f\"  Critical fractile: {CRITICAL_RATIO:.4f} ({CRITICAL_RATIO*100:.2f}%)\")\n",
        "print(f\"  Protection period: {PROTECTION_WEEKS} weeks\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load VN2 Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load sales history\n",
        "sales_df = pd.read_csv(DATA_DIR / \"Week 0 - 2024-04-08 - Sales.csv\")\n",
        "initial_state = pd.read_csv(DATA_DIR / \"Week 0 - 2024-04-08 - Initial State.csv\")\n",
        "template = pd.read_csv(DATA_DIR / \"Week 0 - Submission Template.csv\")\n",
        "\n",
        "# Convert to long format\n",
        "id_cols = [\"Store\", \"Product\"]\n",
        "sales_long = sales_df.melt(id_vars=id_cols, var_name=\"date\", value_name=\"sales_qty\")\n",
        "sales_long[\"date\"] = pd.to_datetime(sales_long[\"date\"])\n",
        "sales_long[\"sales_qty\"] = pd.to_numeric(sales_long[\"sales_qty\"], errors=\"coerce\").fillna(0)\n",
        "sales_long = sales_long.sort_values([\"Store\", \"Product\", \"date\"]).reset_index(drop=True)\n",
        "\n",
        "# Get SKU list (all 599)\n",
        "sku_list = template[[\"Store\", \"Product\"]].copy()\n",
        "\n",
        "print(f\"\\\\n📦 Data Loaded:\")\n",
        "print(f\"  Total SKUs: {len(sku_list)}\")\n",
        "print(f\"  Sales history: {sales_long.shape}\")\n",
        "print(f\"  Weeks of data: {sales_long['date'].nunique()}\")\n",
        "print(f\"  Date range: {sales_long['date'].min()} to {sales_long['date'].max()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load TimesFM 2.5 with Quantile Head\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Loading TimesFM 2.5...\")\n",
        "model = timesfm.TimesFM_2p5_200M_torch.from_pretrained(\"google/timesfm-2.5-200m-pytorch\")\n",
        "\n",
        "print(\"Compiling with quantile head...\")\n",
        "model.compile(\n",
        "    timesfm.ForecastConfig(\n",
        "        max_context=512,\n",
        "        max_horizon=128,\n",
        "        normalize_inputs=True,\n",
        "        use_continuous_quantile_head=True,\n",
        "        force_flip_invariance=True,\n",
        "        infer_is_positive=True,\n",
        "        fix_quantile_crossing=True,\n",
        "    )\n",
        ")\n",
        "print(\"✓ Model ready with quantile forecasting enabled\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Generate Quantile Forecasts (All SKUs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare inputs for all SKUs\n",
        "CONTEXT_LENGTH = 140  # Use last 140 weeks\n",
        "HORIZON = PROTECTION_WEEKS  # 3 weeks\n",
        "\n",
        "inputs = []\n",
        "for idx, row in sku_list.iterrows():\n",
        "    sku_data = sales_long[\n",
        "        (sales_long[\"Store\"] == row[\"Store\"]) &\n",
        "        (sales_long[\"Product\"] == row[\"Product\"])\n",
        "    ].sort_values(\"date\")\n",
        "    \n",
        "    history = sku_data[\"sales_qty\"].values\n",
        "    inputs.append(history[-CONTEXT_LENGTH:] if len(history) >= CONTEXT_LENGTH else history)\n",
        "\n",
        "print(f\"\\\\n🔮 Generating forecasts for {len(inputs)} SKUs...\")\n",
        "print(f\"  Context: {CONTEXT_LENGTH} weeks\")\n",
        "print(f\"  Horizon: {HORIZON} weeks\")\n",
        "\n",
        "# Generate quantile forecasts\n",
        "point_forecast, quantile_forecast = model.forecast(\n",
        "    horizon=HORIZON,\n",
        "    inputs=inputs,\n",
        ")\n",
        "\n",
        "print(f\"\\\\n✓ Forecasts generated!\")\n",
        "print(f\"  Point forecast shape: {point_forecast.shape}\")\n",
        "print(f\"  Quantile forecast shape: {quantile_forecast.shape}\")\n",
        "print(f\"  Quantiles: [mean, P10, P20, P30, P40, P50, P60, P70, P80, P90]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Select Cost-Optimal Quantile\n",
        "\n",
        "Use critical fractile = 0.8333 → closest quantile is P80\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Map critical fractile to closest available quantile\n",
        "quantile_levels = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
        "closest_idx = np.argmin(np.abs(quantile_levels - CRITICAL_RATIO))\n",
        "chosen_quantile = quantile_levels[closest_idx]\n",
        "\n",
        "print(f\"\\\\n💰 Cost-Optimal Quantile Selection:\")\n",
        "print(f\"  Critical fractile: {CRITICAL_RATIO:.4f}\")\n",
        "print(f\"  Closest quantile: P{int(chosen_quantile*100)}\")\n",
        "print(f\"  This means: Order enough to satisfy demand in {chosen_quantile*100:.0f}% of scenarios\")\n",
        "\n",
        "# Extract chosen quantile (add 1 for mean offset in array)\n",
        "optimal_quantile_forecast = quantile_forecast[:, :, closest_idx + 1]\n",
        "print(f\"\\\\n  Selected forecast shape: {optimal_quantile_forecast.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Aggregate to Protection Period\n",
        "\n",
        "Sum 3-week forecasts and estimate uncertainty\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build demand_stats for policy\n",
        "demand_stats = []\n",
        "\n",
        "for i, (idx, sku_row) in enumerate(sku_list.iterrows()):\n",
        "    # 3-week total demand (sum across horizon)\n",
        "    demand_3w = optimal_quantile_forecast[i, :].sum()\n",
        "    \n",
        "    # Estimate std from quantile spread (IQR method)\n",
        "    # P80-P50 gives rough sense of upper tail\n",
        "    q50 = quantile_forecast[i, :, 5].sum()  # Median over 3 weeks\n",
        "    q80 = quantile_forecast[i, :, 8].sum()  # P80 over 3 weeks\n",
        "    \n",
        "    # Rough std estimate: (P80-P50) / 0.84 (z-score for 80th percentile)\n",
        "    std_3w = max((q80 - q50) / 0.84, demand_3w * 0.1)  # Floor at 10% of mean\n",
        "    \n",
        "    demand_stats.append({\n",
        "        \"Store\": sku_row[\"Store\"],\n",
        "        \"Product\": sku_row[\"Product\"],\n",
        "        \"mean_demand\": float(demand_3w),\n",
        "        \"std_demand\": float(std_3w)\n",
        "    })\n",
        "\n",
        "demand_stats_df = pd.DataFrame(demand_stats).set_index([\"Store\", \"Product\"])\n",
        "\n",
        "print(f\"\\\\n📊 Demand Statistics (3-week protection period):\")\n",
        "print(f\"  Mean demand: {demand_stats_df['mean_demand'].mean():.2f} units\")\n",
        "print(f\"  Mean std: {demand_stats_df['std_demand'].mean():.2f} units\")\n",
        "print(f\"  Max demand: {demand_stats_df['mean_demand'].max():.0f} units\")\n",
        "demand_stats_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Generate Orders Using Base-Stock Policy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare current state\n",
        "state = initial_state[[\"Store\", \"Product\", \"End Inventory\", \"In Transit W+1\", \"In Transit W+2\"]].copy()\n",
        "state.rename(columns={\"End Inventory\": \"on_hand\"}, inplace=True)\n",
        "state[\"on_order\"] = state[[\"In Transit W+1\", \"In Transit W+2\"]].sum(axis=1)\n",
        "current_state = state[[\"Store\", \"Product\", \"on_hand\", \"on_order\"]].set_index([\"Store\", \"Product\"])\n",
        "\n",
        "# Get index from template\n",
        "index_df = template[[\"Store\", \"Product\"]].set_index([\"Store\", \"Product\"])\n",
        "\n",
        "# Compute orders\n",
        "print(\"\\\\n🎯 Computing orders...\")\n",
        "orders = compute_orders(\n",
        "    index_df=index_df,\n",
        "    demand_stats=demand_stats_df,\n",
        "    current_state=current_state,\n",
        "    lead_time_weeks=LEAD_WEEKS,\n",
        "    review_period_weeks=REVIEW_WEEKS,\n",
        "    shortage_cost_per_unit=SHORTAGE_COST,\n",
        "    holding_cost_per_unit_per_week=HOLDING_COST,\n",
        ")\n",
        "\n",
        "print(f\"\\\\n✓ Orders computed for {len(orders)} SKUs\")\n",
        "print(f\"  Total units: {orders.sum():,.0f}\")\n",
        "print(f\"  Mean order: {orders.mean():.2f} units\")\n",
        "print(f\"  Median order: {orders.median():.0f} units\")\n",
        "print(f\"  Max order: {orders.max():.0f} units\")\n",
        "print(f\"  Zero orders: {(orders == 0).sum()} SKUs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Submission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create submission DataFrame\n",
        "submission = index_df.copy()\n",
        "submission[\"0\"] = orders.values\n",
        "\n",
        "# Validate\n",
        "assert len(submission) == len(template), \"Row count mismatch!\"\n",
        "assert submission.index.equals(template.set_index([\"Store\", \"Product\"]).index), \"Index mismatch!\"\n",
        "\n",
        "# Save\n",
        "output_path = SUB_DIR / \"orders_timesfm_quantile_demo.csv\"\n",
        "submission.to_csv(output_path)\n",
        "\n",
        "print(f\"\\\\n✅ SUBMISSION SAVED: {output_path}\")\n",
        "print(f\"\\\\n📄 Submission Summary:\")\n",
        "print(f\"  Rows: {len(submission)}\")\n",
        "print(f\"  Columns: {list(submission.columns)}\")\n",
        "print(f\"  Total units ordered: {submission['0'].sum():,.0f}\")\n",
        "print(f\"  Mean order: {submission['0'].mean():.2f}\")\n",
        "print(f\"  Zeros: {(submission['0'] == 0).sum()}\")\n",
        "\n",
        "print(f\"\\\\n🔝 Top 10 Orders:\")\n",
        "top_10 = submission.nlargest(10, \"0\")\n",
        "print(top_10)\n",
        "\n",
        "print(f\"\\\\n💡 This demo shows TimesFM 2.5's quantile forecasting capability.\")\n",
        "print(f\"   Cost-optimal quantile (P80) was automatically selected based on Cu/Co ratio.\")\n",
        "print(f\"   Ready for VN2 submission validation!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
