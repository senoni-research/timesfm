{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VN2 Submission: TimesFM 2.5 Quantile + Covariates Demo\n",
        "\n",
        "**Purpose**: Demonstrate TimesFM 2.5's quantile head WITH COVARIATES for VN2 inventory planning\n",
        "\n",
        "**Enhancement**: Combines `forecast_with_covariates()` + `use_continuous_quantile_head=True`\n",
        "\n",
        "**Approach**:\n",
        "1. Load all 599 SKUs from VN2\n",
        "2. Prepare static (store, product group) + dynamic (month, week) covariates\n",
        "3. Generate quantile forecasts (P10-P90) with covariate adjustments\n",
        "4. Select cost-optimal quantile: Cu/(Cu+Co_period) = 1.0/(1.0+0.6) = 0.625\n",
        "5. Convert to order quantities using base-stock policy\n",
        "6. Generate submission CSV\n",
        "\n",
        "**Note**: This is a DEMO of quantile+covariate forecasting capabilities, not competing with the official hierarchical Bayes submission.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch: 2.8.0\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# TimesFM\n",
        "import torch\n",
        "timesfm_path = Path(\"..\").resolve()\n",
        "if str(timesfm_path) not in sys.path:\n",
        "    sys.path.insert(0, str(timesfm_path))\n",
        "import timesfm\n",
        "\n",
        "# VN2 policy helpers\n",
        "vn2_path = Path(\"../../vn2inventory\").resolve()\n",
        "if str(vn2_path) not in sys.path:\n",
        "    sys.path.insert(0, str(vn2_path))\n",
        "from vn2inventory.policy import compute_orders\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nüìä VN2 Cost Structure:\n",
            "  Shortage cost (Cu): $1.0 per unit\n",
            "  Holding cost (Co): $0.2 per unit per week\n",
            "  Protection period (L+R): 3 weeks\n",
            "  Holding cost (period basis): $0.60\n",
            "  Critical fractile œÑ: 0.6250 (62.50%)\n"
          ]
        }
      ],
      "source": [
        "# VN2 Configuration\n",
        "DATA_DIR = Path(\"../../vn2inventory/data\").resolve()\n",
        "SUB_DIR = Path(\"../../vn2inventory/submissions\").resolve()\n",
        "SUB_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Costs (from VN2 competition)\n",
        "SHORTAGE_COST = 1.0\n",
        "HOLDING_COST = 0.2  # per unit per week\n",
        "LEAD_WEEKS = 2\n",
        "REVIEW_WEEKS = 1\n",
        "PROTECTION_WEEKS = LEAD_WEEKS + REVIEW_WEEKS  # 3 weeks\n",
        "\n",
        "# Critical fractile (Newsvendor optimal service level)\n",
        "# Must use costs on the same time basis (protection period)\n",
        "Co_period = HOLDING_COST * PROTECTION_WEEKS  # Convert weekly ‚Üí protection-period\n",
        "CRITICAL_RATIO = SHORTAGE_COST / (SHORTAGE_COST + Co_period)\n",
        "\n",
        "print(f\"\\\\nüìä VN2 Cost Structure:\")\n",
        "print(f\"  Shortage cost (Cu): ${SHORTAGE_COST} per unit\")\n",
        "print(f\"  Holding cost (Co): ${HOLDING_COST} per unit per week\")\n",
        "print(f\"  Protection period (L+R): {PROTECTION_WEEKS} weeks\")\n",
        "print(f\"  Holding cost (period basis): ${Co_period:.2f}\")\n",
        "print(f\"  Critical fractile œÑ: {CRITICAL_RATIO:.4f} ({CRITICAL_RATIO*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load VN2 Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nüì¶ Data Loaded:\n",
            "  Total SKUs: 599\n",
            "  Sales history: (94043, 4)\n",
            "  Weeks of data: 157\n",
            "  Date range: 2021-04-12 00:00:00 to 2024-04-08 00:00:00\n"
          ]
        }
      ],
      "source": [
        "# Load sales history and master data\n",
        "sales_df = pd.read_csv(DATA_DIR / \"Week 0 - 2024-04-08 - Sales.csv\")\n",
        "master_df = pd.read_csv(DATA_DIR / \"Week 0 - Master.csv\")\n",
        "initial_state = pd.read_csv(DATA_DIR / \"Week 0 - 2024-04-08 - Initial State.csv\")\n",
        "template = pd.read_csv(DATA_DIR / \"Week 0 - Submission Template.csv\")\n",
        "\n",
        "# Strip whitespace from column names (avoid Store_x/Store_y conflicts)\n",
        "sales_df.columns = sales_df.columns.str.strip()\n",
        "master_df.columns = master_df.columns.str.strip()\n",
        "\n",
        "# Convert to long format\n",
        "id_cols = [\"Store\", \"Product\"]\n",
        "assert set(id_cols).issubset(sales_df.columns), f\"Missing id columns in sales_df\"\n",
        "\n",
        "sales_long = sales_df.melt(id_vars=id_cols, var_name=\"date\", value_name=\"sales_qty\")\n",
        "\n",
        "# Normalize columns and types\n",
        "sales_long.columns = sales_long.columns.str.strip()\n",
        "sales_long[\"date\"] = pd.to_datetime(sales_long[\"date\"], errors=\"coerce\")\n",
        "sales_long[\"sales_qty\"] = pd.to_numeric(sales_long[\"sales_qty\"], errors=\"coerce\").fillna(0.0)\n",
        "sales_long[\"Store\"] = pd.to_numeric(sales_long[\"Store\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "sales_long[\"Product\"] = pd.to_numeric(sales_long[\"Product\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "# Add temporal features for dynamic covariates\n",
        "sales_long[\"week_of_year\"] = sales_long[\"date\"].dt.isocalendar().week.astype(int)\n",
        "sales_long[\"month\"] = sales_long[\"date\"].dt.month.astype(int)\n",
        "sales_long[\"quarter\"] = sales_long[\"date\"].dt.quarter.astype(int)\n",
        "\n",
        "# Merge master data (only ProductGroup and Department to avoid Store conflict)\n",
        "master_cols = [\"Product\", \"ProductGroup\", \"Department\"]\n",
        "master_subset = master_df[master_cols].drop_duplicates(subset=[\"Product\"])\n",
        "sales_long = sales_long.merge(master_subset, on=\"Product\", how=\"left\")\n",
        "\n",
        "# Fill missing master data\n",
        "sales_long[\"ProductGroup\"] = sales_long[\"ProductGroup\"].fillna(0).astype(int)\n",
        "sales_long[\"Department\"] = sales_long[\"Department\"].fillna(0).astype(int)\n",
        "\n",
        "# Sort\n",
        "sales_long = sales_long.sort_values([\"Store\", \"Product\", \"date\"]).reset_index(drop=True)\n",
        "\n",
        "# Get SKU list (all 599)\n",
        "sku_list = template[[\"Store\", \"Product\"]].copy()\n",
        "\n",
        "print(f\"\\\\nüì¶ Data Loaded:\")\n",
        "print(f\"  Total SKUs: {len(sku_list)}\")\n",
        "print(f\"  Sales history: {sales_long.shape}\")\n",
        "print(f\"  Columns: {list(sales_long.columns)}\")\n",
        "print(f\"  Weeks of data: {sales_long['date'].nunique()}\")\n",
        "print(f\"  Date range: {sales_long['date'].min()} to {sales_long['date'].max()}\")\n",
        "print(f\"‚úì Master data merged (ProductGroup, Department)\")\n",
        "print(f\"‚úì Temporal features added (week_of_year, month, quarter)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load TimesFM 2.5 with Quantile Head\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading TimesFM 2.5...\n",
            "Compiling with quantile head...\n",
            "‚úì Model ready with quantile forecasting enabled\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading TimesFM 2.5...\")\n",
        "model = timesfm.TimesFM_2p5_200M_torch.from_pretrained(\"google/timesfm-2.5-200m-pytorch\")\n",
        "\n",
        "print(\"Compiling with quantile head...\")\n",
        "model.compile(\n",
        "    timesfm.ForecastConfig(\n",
        "        max_context=512,\n",
        "        max_horizon=128,\n",
        "        normalize_inputs=True,\n",
        "        use_continuous_quantile_head=True,\n",
        "        force_flip_invariance=True,\n",
        "        infer_is_positive=True,\n",
        "        fix_quantile_crossing=True,\n",
        "    )\n",
        ")\n",
        "print(\"‚úì Model ready with quantile forecasting enabled\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.5. Prepare Covariates\n",
        "\n",
        "Extract static and dynamic covariates for all SKUs to enhance forecasts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare covariates for all SKUs\n",
        "CONTEXT_LENGTH = 140\n",
        "HORIZON = 3\n",
        "\n",
        "# Verify required columns exist\n",
        "required_cols = {\"Store\", \"Product\", \"date\", \"sales_qty\", \"month\", \"week_of_year\", \"quarter\", \"ProductGroup\", \"Department\"}\n",
        "missing = required_cols - set(sales_long.columns)\n",
        "assert not missing, f\"Missing required columns in sales_long: {missing}\"\n",
        "\n",
        "static_categorical_covariates = {\"store\": [], \"product_group\": [], \"department\": []}\n",
        "static_numerical_covariates = {\"mean_demand\": [], \"cv_demand\": []}\n",
        "dynamic_categorical_covariates = {\"month\": [], \"week_of_year\": [], \"quarter\": []}\n",
        "dynamic_numerical_covariates = {\"week_index\": []}\n",
        "\n",
        "for idx, row in sku_list.iterrows():\n",
        "    sku_data = sales_long[\n",
        "        (sales_long[\"Store\"] == row[\"Store\"]) &\n",
        "        (sales_long[\"Product\"] == row[\"Product\"])\n",
        "    ].sort_values(\"date\")\n",
        "    \n",
        "    if sku_data.empty:\n",
        "        continue\n",
        "    \n",
        "    # Static features\n",
        "    static_categorical_covariates[\"store\"].append(int(row[\"Store\"]))\n",
        "    static_categorical_covariates[\"product_group\"].append(int(sku_data.iloc[0][\"ProductGroup\"]))\n",
        "    static_categorical_covariates[\"department\"].append(int(sku_data.iloc[0][\"Department\"]))\n",
        "    \n",
        "    mean_demand = float(sku_data[\"sales_qty\"].mean())\n",
        "    std_demand = float(sku_data[\"sales_qty\"].std())\n",
        "    cv_demand = (std_demand / mean_demand) if mean_demand > 0 else 0.0\n",
        "    static_numerical_covariates[\"mean_demand\"].append(mean_demand)\n",
        "    static_numerical_covariates[\"cv_demand\"].append(cv_demand)\n",
        "    \n",
        "    # Dynamic features (context + horizon)\n",
        "    # We need CONTEXT_LENGTH + HORIZON values for dynamic covariates\n",
        "    history = sku_data if len(sku_data) >= CONTEXT_LENGTH else sku_data\n",
        "    context_data = history.iloc[-CONTEXT_LENGTH:] if len(history) >= CONTEXT_LENGTH else history\n",
        "    \n",
        "    # For horizon, we need future covariates\n",
        "    # Since we don't have actual future dates, extrapolate from last known date\n",
        "    last_date = context_data[\"date\"].iloc[-1]\n",
        "    future_dates = pd.date_range(start=last_date + pd.Timedelta(weeks=1), periods=HORIZON, freq=\"W-MON\")\n",
        "    \n",
        "    # Combine context + horizon temporal features\n",
        "    context_months = context_data[\"month\"].tolist()\n",
        "    context_weeks = context_data[\"week_of_year\"].tolist()\n",
        "    context_quarters = context_data[\"quarter\"].tolist()\n",
        "    \n",
        "    future_months = [int(d.month) for d in future_dates]\n",
        "    future_weeks = [int(d.isocalendar().week) for d in future_dates]\n",
        "    future_quarters = [int((d.month - 1) // 3 + 1) for d in future_dates]\n",
        "    \n",
        "    dynamic_categorical_covariates[\"month\"].append(context_months + future_months)\n",
        "    dynamic_categorical_covariates[\"week_of_year\"].append(context_weeks + future_weeks)\n",
        "    dynamic_categorical_covariates[\"quarter\"].append(context_quarters + future_quarters)\n",
        "    dynamic_numerical_covariates[\"week_index\"].append(list(range(len(context_data) + HORIZON)))\n",
        "\n",
        "print(f\"\\\\n‚úì Covariates prepared for {len(sku_list)} SKUs\")\n",
        "print(f\"  Static categorical: {list(static_categorical_covariates.keys())}\")\n",
        "print(f\"  Static numerical: {list(static_numerical_covariates.keys())}\")\n",
        "print(f\"  Dynamic categorical: {list(dynamic_categorical_covariates.keys())}\")\n",
        "print(f\"  Dynamic numerical: {list(dynamic_numerical_covariates.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Generate Quantile Forecasts (All SKUs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nüîÆ Generating forecasts for 599 SKUs...\n",
            "  Context: 140 weeks\n",
            "  Horizon: 3 weeks\n",
            "\\n‚úì Forecasts generated!\n",
            "  Point forecast shape: (599, 3)\n",
            "  Quantile forecast shape: (599, 3, 10)\n",
            "  Quantiles: [mean, P10, P20, P30, P40, P50, P60, P70, P80, P90]\n",
            "  ‚úì Quantile tensor format validated\n"
          ]
        }
      ],
      "source": [
        "# Prepare inputs for all SKUs\n",
        "inputs = []\n",
        "for idx, row in sku_list.iterrows():\n",
        "    sku_data = sales_long[\n",
        "        (sales_long[\"Store\"] == row[\"Store\"]) &\n",
        "        (sales_long[\"Product\"] == row[\"Product\"])\n",
        "    ].sort_values(\"date\")\n",
        "    \n",
        "    history = sku_data[\"sales_qty\"].values\n",
        "    inputs.append(history[-CONTEXT_LENGTH:] if len(history) >= CONTEXT_LENGTH else history)\n",
        "\n",
        "print(f\"\\\\nüîÆ Generating quantile forecasts WITH COVARIATES for {len(inputs)} SKUs...\")\n",
        "print(f\"  Context: {CONTEXT_LENGTH} weeks\")\n",
        "print(f\"  Horizon: {HORIZON} weeks\")\n",
        "print(f\"  Covariates: Store, ProductGroup, Department, temporal features\")\n",
        "\n",
        "# Generate quantile forecasts WITH COVARIATES\n",
        "combined_forecast, xreg_forecast, quantile_forecast_list = model.forecast_with_covariates(\n",
        "    horizon=HORIZON,\n",
        "    inputs=inputs,\n",
        "    static_categorical_covariates=static_categorical_covariates,\n",
        "    static_numerical_covariates=static_numerical_covariates,\n",
        "    dynamic_categorical_covariates=dynamic_categorical_covariates,\n",
        "    dynamic_numerical_covariates=dynamic_numerical_covariates,\n",
        "    xreg_mode=\"xreg + timesfm\",  # Recommended mode\n",
        ")\n",
        "\n",
        "# Convert to arrays\n",
        "point_forecast = np.array(combined_forecast)\n",
        "quantile_forecast = np.array(quantile_forecast_list)\n",
        "\n",
        "print(f\"\\\\n‚úì Forecasts generated with covariates!\")\n",
        "print(f\"  Point forecast shape: {point_forecast.shape}\")\n",
        "print(f\"  Quantile forecast shape: {quantile_forecast.shape}\")\n",
        "print(f\"  Quantiles: [mean, P10, P20, P30, P40, P50, P60, P70, P80, P90]\")\n",
        "\n",
        "# Runtime assertion for API consistency\n",
        "assert quantile_forecast.shape[-1] == 10, \"Expected last dim = 10 ([mean, P10..P90])\"\n",
        "print(\"  ‚úì Quantile tensor format validated\")\n",
        "print(\"  ‚úì Covariate adjustments applied to all quantile levels\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Select Cost-Optimal Quantile\n",
        "\n",
        "Compute critical fractile œÑ = Cu/(Cu+Co_period), then round to nearest available quantile in grid [P10..P90].\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nüí∞ Cost-Optimal Quantile Selection:\n",
            "  Critical fractile œÑ: 0.6250 (‚âà P62)\n",
            "  Closest grid quantile: P60 (nearest to œÑ*=0.625)\n",
            "  Protection period: 3 weeks (lead + review)\n",
            "  This means: Order to satisfy demand in 60% of protection-period scenarios\n",
            "\\n  Selected forecast shape: (599, 3)\n"
          ]
        }
      ],
      "source": [
        "# Map critical fractile to closest available quantile in grid\n",
        "quantile_levels = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
        "closest_idx = np.argmin(np.abs(quantile_levels - CRITICAL_RATIO))\n",
        "chosen_quantile = quantile_levels[closest_idx]\n",
        "\n",
        "print(f\"\\\\nüí∞ Cost-Optimal Quantile Selection:\")\n",
        "print(f\"  Critical fractile œÑ: {CRITICAL_RATIO:.4f} (‚âà P{int(CRITICAL_RATIO*100)})\")\n",
        "print(f\"  Closest grid quantile: P{int(chosen_quantile*100)} (nearest to œÑ*={CRITICAL_RATIO:.3f})\")\n",
        "print(f\"  Protection period: {PROTECTION_WEEKS} weeks (lead + review)\")\n",
        "print(f\"  This means: Order to satisfy demand in {chosen_quantile*100:.0f}% of protection-period scenarios\")\n",
        "\n",
        "# Extract chosen quantile (add 1 for mean offset in array)\n",
        "optimal_quantile_forecast = quantile_forecast[:, :, closest_idx + 1]\n",
        "print(f\"\\\\n  Selected forecast shape: {optimal_quantile_forecast.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Aggregate to Protection Period\n",
        "\n",
        "Sum 3-week forecasts and estimate uncertainty\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nüìä Demand Statistics (3-week protection period):\n",
            "  Mean demand: 9.13 units\n",
            "  Mean std: 6.50 units\n",
            "  Max demand: 302 units\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>mean_demand</th>\n",
              "      <th>std_demand</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Store</th>\n",
              "      <th>Product</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>126</th>\n",
              "      <td>7.087064</td>\n",
              "      <td>7.419773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>3.162152</td>\n",
              "      <td>2.744097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <th>124</th>\n",
              "      <td>24.379612</td>\n",
              "      <td>13.054598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
              "      <th>124</th>\n",
              "      <td>26.680462</td>\n",
              "      <td>13.731553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>7.508129</td>\n",
              "      <td>7.485362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               mean_demand  std_demand\n",
              "Store Product                         \n",
              "0     126         7.087064    7.419773\n",
              "      182         3.162152    2.744097\n",
              "1     124        24.379612   13.054598\n",
              "2     124        26.680462   13.731553\n",
              "      126         7.508129    7.485362"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Build demand_stats for policy\n",
        "demand_stats = []\n",
        "\n",
        "for i, (idx, sku_row) in enumerate(sku_list.iterrows()):\n",
        "    # 3-week total demand (sum across horizon)\n",
        "    demand_3w = optimal_quantile_forecast[i, :].sum()\n",
        "    \n",
        "    # Estimate std from P80-P50 spread (Normal approx)\n",
        "    # Note: Summing weekly quantiles is an approximation;\n",
        "    # it slightly underestimates tail risk if weeks are positively correlated.\n",
        "    # For high-stakes items, simulate the period distribution instead.\n",
        "    q50 = quantile_forecast[i, :, 5].sum()  # Median over 3 weeks\n",
        "    q80 = quantile_forecast[i, :, 8].sum()  # P80 over 3 weeks\n",
        "    \n",
        "    # Rough std estimate: sigma ‚âà (P80-P50) / 0.8416  (z_0.80 ‚âà 0.8416)\n",
        "    # Alternative: sigma ‚âà (P90 - P10) / 2.5632 (more robust)\n",
        "    std_3w = max((q80 - q50) / 0.8416, demand_3w * 0.1)  # Floor at 10% of mean\n",
        "    \n",
        "    demand_stats.append({\n",
        "        \"Store\": sku_row[\"Store\"],\n",
        "        \"Product\": sku_row[\"Product\"],\n",
        "        \"mean_demand\": float(demand_3w),\n",
        "        \"std_demand\": float(std_3w)\n",
        "    })\n",
        "\n",
        "demand_stats_df = pd.DataFrame(demand_stats).set_index([\"Store\", \"Product\"])\n",
        "\n",
        "print(f\"\\\\nüìä Demand Statistics (3-week protection period):\")\n",
        "print(f\"  Mean demand: {demand_stats_df['mean_demand'].mean():.2f} units\")\n",
        "print(f\"  Mean std: {demand_stats_df['std_demand'].mean():.2f} units\")\n",
        "print(f\"  Max demand: {demand_stats_df['mean_demand'].max():.0f} units\")\n",
        "demand_stats_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Generate Orders Using Base-Stock Policy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nüéØ Computing orders...\n",
            "\\n‚úì Orders computed for 599 SKUs\n",
            "  Total units: 17,454\n",
            "  Mean order: 29.14 units\n",
            "  Median order: 12 units\n",
            "  Max order: 924 units\n",
            "  Zero orders: 3 SKUs\n"
          ]
        }
      ],
      "source": [
        "# Prepare current state\n",
        "state = initial_state[[\"Store\", \"Product\", \"End Inventory\", \"In Transit W+1\", \"In Transit W+2\"]].copy()\n",
        "state.rename(columns={\"End Inventory\": \"on_hand\"}, inplace=True)\n",
        "state[\"on_order\"] = state[[\"In Transit W+1\", \"In Transit W+2\"]].sum(axis=1)\n",
        "current_state = state[[\"Store\", \"Product\", \"on_hand\", \"on_order\"]].set_index([\"Store\", \"Product\"])\n",
        "\n",
        "# Get index from template\n",
        "index_df = template[[\"Store\", \"Product\"]].set_index([\"Store\", \"Product\"])\n",
        "\n",
        "# Compute orders\n",
        "print(\"\\\\nüéØ Computing orders...\")\n",
        "orders = compute_orders(\n",
        "    index_df=index_df,\n",
        "    demand_stats=demand_stats_df,\n",
        "    current_state=current_state,\n",
        "    lead_time_weeks=LEAD_WEEKS,\n",
        "    review_period_weeks=REVIEW_WEEKS,\n",
        "    shortage_cost_per_unit=SHORTAGE_COST,\n",
        "    holding_cost_per_unit_per_week=HOLDING_COST,\n",
        ")\n",
        "\n",
        "print(f\"\\\\n‚úì Orders computed for {len(orders)} SKUs\")\n",
        "print(f\"  Total units: {orders.sum():,.0f}\")\n",
        "print(f\"  Mean order: {orders.mean():.2f} units\")\n",
        "print(f\"  Median order: {orders.median():.0f} units\")\n",
        "print(f\"  Max order: {orders.max():.0f} units\")\n",
        "print(f\"  Zero orders: {(orders == 0).sum()} SKUs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Submission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\n‚úÖ SUBMISSION SAVED: /Users/senoni/noni/vn2inventory/submissions/orders_timesfm_quantile_demo.csv\n",
            "\\nüìÑ Submission Summary:\n",
            "  Rows: 599\n",
            "  Columns: ['0']\n",
            "  Total units ordered: 17,454\n",
            "  Mean order: 29.14\n",
            "  Zeros: 3\n",
            "\\nüîù Top 10 Orders:\n",
            "                 0\n",
            "Store Product     \n",
            "61    23       924\n",
            "      124      703\n",
            "63    124      596\n",
            "60    125      582\n",
            "62    23       557\n",
            "60    23       489\n",
            "63    23       485\n",
            "64    17       396\n",
            "      23       351\n",
            "61    48       289\n",
            "\\nüí° This demo shows TimesFM 2.5's quantile forecasting capability.\n",
            "   Cost-optimal quantile (P80) was automatically selected based on Cu/Co ratio.\n",
            "   Ready for VN2 submission validation!\n"
          ]
        }
      ],
      "source": [
        "# Create submission DataFrame\n",
        "submission = index_df.copy()\n",
        "submission[\"0\"] = orders.values\n",
        "\n",
        "# Validate\n",
        "assert len(submission) == len(template), \"Row count mismatch!\"\n",
        "assert submission.index.equals(template.set_index([\"Store\", \"Product\"]).index), \"Index mismatch!\"\n",
        "\n",
        "# Save\n",
        "output_path = SUB_DIR / \"orders_timesfm_quantile_covariates_demo.csv\"\n",
        "submission.to_csv(output_path)\n",
        "\n",
        "print(f\"\\\\n‚úÖ SUBMISSION SAVED: {output_path}\")\n",
        "print(f\"\\\\nüìÑ Submission Summary:\")\n",
        "print(f\"  Rows: {len(submission)}\")\n",
        "print(f\"  Columns: {list(submission.columns)}\")\n",
        "print(f\"  Total units ordered: {submission['0'].sum():,.0f}\")\n",
        "print(f\"  Mean order: {submission['0'].mean():.2f}\")\n",
        "print(f\"  Zeros: {(submission['0'] == 0).sum()}\")\n",
        "\n",
        "print(f\"\\\\nüîù Top 10 Orders:\")\n",
        "top_10 = submission.nlargest(10, \"0\")\n",
        "print(top_10)\n",
        "\n",
        "print(f\"\\\\nüí° This demo shows TimesFM 2.5's quantile + covariate forecasting capability.\")\n",
        "print(f\"   Covariates (Store, ProductGroup, Department, temporal) enhance distributional forecasts.\")\n",
        "print(f\"   Cost-optimal quantile (P60) was automatically selected based on Cu/Co ratio.\")\n",
        "print(f\"   Ready for VN2 submission validation!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
